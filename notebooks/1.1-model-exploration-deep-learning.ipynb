{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20923530-3386-4c81-ad16-c9bce6447318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/svenvanderburg/projects/modys-video\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab38e60-9e12-4544-9b00-d3487b63a720",
   "metadata": {},
   "source": [
    "# Experiment 1.1 Explore models and approaches for deep learning\n",
    "Finetune models on left leg amplitude prediction with lying videos as input.\n",
    "For now this is just to quickly test the settings that Shankara got out of previous experiments, i.e.:\n",
    "\n",
    "* Cutoff first 50 frames\n",
    "* Interpolate when likelihood is below 0.7\n",
    "* Use opposite bodypart if all likelihood is below 0.7 for a bodypart\n",
    "* Use a standard scaler to scale\n",
    "    \n",
    "\n",
    "We don't really know whether this is the best set of hyperparameters. We can further experiment with the following hyperparameters:\n",
    "* Use a StandardScaler\n",
    "* Include likelihood\n",
    "* Use different model architectures\n",
    "* Use interpolation\n",
    "* write one function that takes in parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667a9217-95f7-4ca6-a0df-ed551d613239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "from src.helpers import read_scores\n",
    "from src.data_generators import RawDataGenerator\n",
    "from src.data_selection import MultipleScoreSelector\n",
    "from src.ai_func import cross_validation_generator\n",
    "from src.settings import LYING_VIDEOS_DATA_FOLDER, SITTING_VIDEOS_DATA_FOLDER, DATA_FOLDER\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c220eb38-d44f-461c-98b2-fc3b0e573d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = read_scores(DATA_FOLDER / 'data_Scoring_DIS_proximal_trunk_V1.1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee56d8c-7888-4061-b44d-d57ddaee74d2",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef9fbe1-70ae-414b-8d73-f731b1a6f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES_TO_USE = ['D_LLP_R_tA_pscore']\n",
    "SCORER_TO_USE = 1\n",
    "\n",
    "data_generation_params = {\n",
    "    'videos_folder': LYING_VIDEOS_DATA_FOLDER,\n",
    "    'cutoff': 50,\n",
    "    'interpolation_threshold': 0.7,\n",
    "    'batch_size': 1\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaaf614-abc9-48cc-8189-19ac1c8c4f97",
   "metadata": {},
   "source": [
    "## Pipeline for training a deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029b6c1-fd38-45ee-a1b3-59545f1b009e",
   "metadata": {},
   "source": [
    "### Define model architecture (here: simple CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61ad9248-801b-48d4-91db-85b69fc6fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svenvanderburg/projects/modys-video/src/data_selection.py:24: UserWarning: Dropping rows ['096'] with missing video\n",
      "  warnings.warn(f'Dropping rows {missing_ids} with missing video')\n",
      "/Users/svenvanderburg/projects/modys-video/src/data_selection.py:34: UserWarning: Dropping rows ['090' '058' '048'] with missing score\n",
      "  warnings.warn(f'Dropping rows {only_na.index.values} with missing score')\n"
     ]
    }
   ],
   "source": [
    "# Generate some dev data to get X shape\n",
    "selector = MultipleScoreSelector(scores_to_use=SCORES_TO_USE, scorer_to_use=SCORER_TO_USE)\n",
    "dev_selection = selector.transform(scores_df)\n",
    "dev_generator = RawDataGenerator(dev_selection, **data_generation_params)\n",
    "X, y = dev_generator.__getitem__(0)\n",
    "n_timesteps, n_features = (X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a1d312a-cf34-4232-9fd1-df8e41d6f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 449, 64)           3520      \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 447, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 223, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 219, 32)           10272     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 215, 32)           5152      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 107, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3424)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               342500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 373,897\n",
      "Trainable params: 373,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_outputs = len(SCORES_TO_USE)\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=32, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_old():\n",
    "    # simple CNN\n",
    "    input_layer = keras.layers.Input(shape=(n_timesteps,n_features))\n",
    "    norm_layer = keras.layers.BatchNormalization()(input_layer)\n",
    "    cnn_layer = keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu')(norm_layer)\n",
    "    cnn_layer = keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu')(cnn_layer)\n",
    "    cnn_layer = keras.layers.MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "    cnn_layer = keras.layers.Dropout(0.7)(cnn_layer)\n",
    "    cnn_layer = keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_layer)\n",
    "    cnn_layer = keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_layer)\n",
    "    cnn_layer = keras.layers.MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "    cnn_layer = keras.layers.Dropout(0.7)(cnn_layer)\n",
    "    cnn_layer = keras.layers.Flatten()(cnn_layer)\n",
    "    cnn_layer = keras.layers.Dense(100)(cnn_layer)\n",
    "    output_layer = keras.layers.Dense(n_outputs)(cnn_layer)\n",
    "\n",
    "    return keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11614205-da67-494e-8bd9-649b821eb6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6449a3d4-aade-4d03-b57f-5dd4facfa15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_generator):\n",
    "    model = get_model()\n",
    "    model.compile(loss='mae', optimizer=keras.optimizers.Adam())\n",
    "    model.fit(train_generator, epochs=30)\n",
    "    return model\n",
    "\n",
    "def train_cross_val(cross_val):\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "    for i_split, (train_scores, test_scores) in enumerate(cross_val):\n",
    "        print(f'Fitting for 5-fold split {i_split}')\n",
    "        train_generator = RawDataGenerator(train_scores, **data_generation_params)\n",
    "        test_generator = RawDataGenerator(test_scores, **data_generation_params)\n",
    "        model = train_model(train_generator)\n",
    "        y_pred.append(model.predict(test_generator))\n",
    "        y_test.append(test_scores)\n",
    "        break # This results in training only for one of the 5 folds\n",
    "    y_pred = np.vstack(y_pred)\n",
    "    y_test = pd.concat(y_test)\n",
    "    return y_test, y_pred\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    results = []\n",
    "    for i_score, column in enumerate(y_test):\n",
    "        mae = mean_absolute_error(y_test.iloc[:, i_score], y_pred[:, i_score])\n",
    "        results.append({'score': column, 'mae': mae})\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f165050b-5ab3-4faf-9382-a497f74edb96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for scorer 1\n",
      "Fitting for 5-fold split 0\n",
      "Epoch 1/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 94.4572\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 4.9354\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.9040\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 9.7069\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.3360\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.2331\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.2352\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2347\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.2346\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.2313\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2387\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.2328\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2579\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2485\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.2384\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.2363\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.2367\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2392\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 2s 36ms/step - loss: 0.2310\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2334\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.2327\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.2311\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.2328\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2352\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.2342\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.2334\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2320\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.2324\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 2s 34ms/step - loss: 0.2329\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 0.2347\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model for scorer {SCORER_TO_USE}')\n",
    "selector = MultipleScoreSelector(scores_to_use=SCORES_TO_USE, scorer_to_use=SCORER_TO_USE)\n",
    "selected_data = selector.transform(scores_df)\n",
    "cross_val = cross_validation_generator(selected_data)\n",
    "y_test, y_pred = train_cross_val(cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "babe0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               score       mae\n",
      "0  D_LLP_R_tA_pscore  0.103936\n"
     ]
    }
   ],
   "source": [
    "print(evaluate(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
